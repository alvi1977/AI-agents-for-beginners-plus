{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoGen Tool Use Example "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the Needed Packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_core.models import UserMessage\n",
    "from autogen_ext.models.azure import AzureAIChatCompletionClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from autogen_core import CancellationToken\n",
    "from autogen_core.tools import FunctionTool\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.ui import Console\n",
    "from typing import Any, Callable, Set, Dict, List, Optional\n",
    "\n",
    "# Opik imports\n",
    "import opik\n",
    "from opik import track\n",
    "from opik.evaluation.metrics import Hallucination, AnswerRelevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Opik environment variables\n",
    "os.environ[\"OPIK_API_KEY\"] = \"Opik Key\"\n",
    "os.environ[\"OPIK_PROJECT_NAME\"] = \"react_agent\"\n",
    "os.environ[\"OPIK_WORKSPACE\"] = \"alvi77\"\n",
    "os.environ[\"OPIK_ENABLED\"] = \"true\"\n",
    "\n",
    "# Initialize Opik client\n",
    "opik_client = opik.Opik()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Client \n",
    "\n",
    "In this sample, we will use [GitHub Models](https://aka.ms/ai-agents-beginners/github-models) for access to the LLM. \n",
    "\n",
    "The `model` is defined as `gpt-4o-mini`. Try changing the model to another model available on the GitHub Models marketplace to see the different results. \n",
    "\n",
    "As a quick test, we will just run a simple prompt - `What is the capital of France`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish_reason='stop' content='The capital of France is Paris.' usage=RequestUsage(prompt_tokens=14, completion_tokens=8) cached=False logprobs=None thought=None\n"
     ]
    }
   ],
   "source": [
    "client = AzureAIChatCompletionClient(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    endpoint=\"https://models.inference.ai.azure.com\",\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings.\n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    credential=AzureKeyCredential(os.environ[\"GITHUB_TOKEN\"]),\n",
    "    model_info={\n",
    "        \"json_output\": True,\n",
    "        \"function_calling\": True,\n",
    "        \"vision\": True,\n",
    "        \"family\": \"unknown\",\n",
    "    },\n",
    ")\n",
    "\n",
    "result = await client.create([UserMessage(content=\"What is the capital of France?\", source=\"user\")])\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Functions \n",
    "\n",
    "In this example, we will give the agent access to a tool that is a function with a list of available vacation destinations and their availability. \n",
    "\n",
    "You can think that this would be a scenario where a travel agent might have an access to a travel database for example. \n",
    "\n",
    "As you go through this sample, feel free to try to define new functions and tools that the agent can call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional\n",
    "\n",
    "\n",
    "@track(name=\"vacation_destinations_tool\")\n",
    "def vacation_destinations(city: str) -> tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Checks if a specific vacation destination is available\n",
    "    \n",
    "    Args:\n",
    "        city (str): Name of the city to check\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Contains city name and availability status ('Available' or 'Unavailable')\n",
    "    \"\"\"\n",
    "    destinations = {\n",
    "        \"Barcelona\": \"Available\",\n",
    "        \"Tokyo\": \"Unavailable\",\n",
    "        \"Cape Town\": \"Available\",\n",
    "        \"Vancouver\": \"Available\",\n",
    "        \"Dubai\": \"Unavailable\",\n",
    "    }\n",
    "\n",
    "    if city in destinations:\n",
    "        result = city, destinations[city]\n",
    "    else:\n",
    "        result = city, \"City not found\"\n",
    "    \n",
    "       \n",
    "    return result\n",
    "\n",
    "@track(name=\"weather_check_tool\")\n",
    "def check_weather(city: str) -> tuple[str, str, str]:\n",
    "    \"\"\"\n",
    "    Checks the current weather for a specific city\n",
    "    \n",
    "    Args:\n",
    "        city (str): Name of the city to check weather for\n",
    "        \n",
    "    Returns:\n",
    "        tuple: Contains city name, weather condition, and temperature\n",
    "    \"\"\"\n",
    "    # Simple mock weather data\n",
    "    weather_data = {\n",
    "        \"Barcelona\": (\"Sunny\", \"24°C\"),\n",
    "        \"Tokyo\": (\"Cloudy\", \"18°C\"),\n",
    "        \"Cape Town\": (\"Windy\", \"22°C\"),\n",
    "        \"Vancouver\": (\"Rainy\", \"15°C\"),\n",
    "        \"Dubai\": (\"Hot\", \"35°C\"),\n",
    "        \"Berlin\": (\"Cool\", \"12°C\"),\n",
    "        \"Paris\": (\"Mild\", \"19°C\"),\n",
    "        \"London\": (\"Foggy\", \"16°C\"),\n",
    "    }\n",
    "\n",
    "    if city in weather_data:\n",
    "        condition, temp = weather_data[city]\n",
    "        result = city, condition, temp\n",
    "    else:\n",
    "        result = city, \"Unknown\", \"N/A\"\n",
    "    \n",
    "    \n",
    "    return result\n",
    "# Example usage:\n",
    "# city, status = vacation_destinations(\"Barcelona\")\n",
    "# print(f\"How about visiting {city}? It's currently {status} there!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Function Tool \n",
    "To have the agent use the `vacation_destinations` as a `FunctionTool`, we need to define it as one. \n",
    "\n",
    "We will also provide a description of the to tool which is helpful for the agent to identify what that tool is used for in relation to the task the user has requested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create both tools\n",
    "get_vacations = FunctionTool(\n",
    "    vacation_destinations, description=\"Search for vacation destinations and if they are available or not.\"\n",
    ")\n",
    "\n",
    "get_weather = FunctionTool(\n",
    "    check_weather, description=\"Check current weather conditions and temperature for any city.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the agent \n",
    "\n",
    "Now we can create the agent in the below code. We define the `system_message` to give the agent instructions on how to help users find vacation destinations. \n",
    "\n",
    "We also set the `reflect_on_tool_use` parameter to true. This allows use the LLM to take the response of the tool call and send the response using natural language. \n",
    "\n",
    "You can set the the parameter to false to see the difference. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = AssistantAgent(\n",
    "    name=\"assistant\",\n",
    "    model_client=client,\n",
    "    tools=[get_vacations, get_weather],\n",
    "    system_message=\"You are a travel agent that helps users find vacation destinations.\",\n",
    "    reflect_on_tool_use=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Agent \n",
    "\n",
    "Now we can run the agent with the initial user message asking to take a trip to Tokyo. \n",
    "\n",
    "You can change this city desintation to see how the agent responds to the availablity of the city. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=128, completion_tokens=18), content=[FunctionCall(id='call_plnQZUNA4Bf8v9DuCuYYyPgt', arguments='{\"city\":\"Tokyo\"}', name='vacation_destinations')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, content=[FunctionExecutionResult(content=\"('Tokyo', 'Unavailable')\", call_id='call_plnQZUNA4Bf8v9DuCuYYyPgt')], type='ToolCallExecutionEvent')]\n",
      "source='assistant' models_usage=RequestUsage(prompt_tokens=119, completion_tokens=79) content=\"It looks like I'm unable to provide specific details about Tokyo at this moment. However, I can suggest that the best time to visit Tokyo typically falls during the spring (March to May) and autumn (September to November) when the weather is mild and pleasant, with cherry blossoms in spring and beautiful autumn foliage. If you have other destinations in mind, I can help with those as well!\" type='TextMessage'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response(chat_message=TextMessage(source='assistant', models_usage=RequestUsage(prompt_tokens=119, completion_tokens=79), content=\"It looks like I'm unable to provide specific details about Tokyo at this moment. However, I can suggest that the best time to visit Tokyo typically falls during the spring (March to May) and autumn (September to November) when the weather is mild and pleasant, with cherry blossoms in spring and beautiful autumn foliage. If you have other destinations in mind, I can help with those as well!\", type='TextMessage'), inner_messages=[ToolCallRequestEvent(source='assistant', models_usage=RequestUsage(prompt_tokens=128, completion_tokens=18), content=[FunctionCall(id='call_plnQZUNA4Bf8v9DuCuYYyPgt', arguments='{\"city\":\"Tokyo\"}', name='vacation_destinations')], type='ToolCallRequestEvent'), ToolCallExecutionEvent(source='assistant', models_usage=None, content=[FunctionExecutionResult(content=\"('Tokyo', 'Unavailable')\", call_id='call_plnQZUNA4Bf8v9DuCuYYyPgt')], type='ToolCallExecutionEvent')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@track(name=\"travel_agent_conversation\")\n",
    "async def assistant_run(user_query: str = \"I would like to take a trip to Tokyo\") -> None:\n",
    "    \"\"\"\n",
    "    Run the travel agent with Opik tracking for evaluation\n",
    "    \"\"\"\n",
    "    \n",
    "    # Track the full conversation\n",
    "    response = await agent.on_messages(\n",
    "        [TextMessage(content=user_query, source=\"user\")],\n",
    "        cancellation_token=CancellationToken(),\n",
    "    )\n",
    "    \n",
    "    # Extract tool usage information for evaluation\n",
    "    tool_calls = []\n",
    "    for msg in response.inner_messages:\n",
    "        if hasattr(msg, 'content') and isinstance(msg.content, list):\n",
    "            for item in msg.content:\n",
    "                if hasattr(item, 'name') and hasattr(item, 'arguments'):\n",
    "                    tool_calls.append({\n",
    "                        \"tool_name\": item.name,\n",
    "                        \"arguments\": item.arguments,\n",
    "                        \"call_id\": getattr(item, 'id', 'unknown')\n",
    "                    })\n",
    "    \n",
    "    print(response.inner_messages)\n",
    "    print(response.chat_message)\n",
    "    \n",
    "    return response\n",
    "\n",
    "\n",
    "# Use asyncio.run(assistant_run()) when running in a script.\n",
    "await assistant_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azure_ai_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
